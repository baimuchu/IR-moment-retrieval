{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdYzrLhxMTlW",
        "outputId": "f098c2dd-15fa-49fa-8a3e-6bd614661a65"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UmQotmJMUrs",
        "outputId": "63f171cd-ae67-4549-80f8-f3ac3825cd24"
      },
      "outputs": [],
      "source": [
        "pip install python-terrier==0.10.0 nltk scikit-learn lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYhewvEjL-7Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import pyterrier as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W17JgCyFL-7Z"
      },
      "outputs": [],
      "source": [
        "# Paths to JSONL files\n",
        "jsonl_train_path = 'text_data/tvr_train_release.jsonl'\n",
        "jsonl_val_path = 'text_data/tvr_val_release.jsonl'\n",
        "subs_path = 'text_data/tvqa_preprocessed_subtitles.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UruQwRMsOrNj"
      },
      "outputs": [],
      "source": [
        "# Paths to JSONL files on Colab\n",
        "jsonl_train_path = '/content/drive/MyDrive/IR/text_data/tvr_train_release.jsonl'\n",
        "jsonl_val_path = '/content/drive/MyDrive/IR/text_data/tvr_val_release.jsonl'\n",
        "subs_path = '/content/drive/MyDrive/IR/text_data/tvqa_preprocessed_subtitles.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6VZMDuDL-7Z"
      },
      "outputs": [],
      "source": [
        "# Load subtitles into a dictionary for quick access\n",
        "subtitles_dict = {}\n",
        "with open(subs_path, 'r') as subs_file:\n",
        "    for line in subs_file:\n",
        "        sub_data = json.loads(line)\n",
        "        subtitles_dict[sub_data['vid_name']] = sub_data['sub']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkWQOjjYL-7Z"
      },
      "outputs": [],
      "source": [
        "# Function to find matching subtitles\n",
        "def find_matching_subtitles(vid_name, ts_range, subtitles_dict):\n",
        "    matching_subs = []\n",
        "    if vid_name in subtitles_dict:\n",
        "        for subtitle in subtitles_dict[vid_name]:\n",
        "            if (ts_range[0] <= subtitle['start'] <= ts_range[1]) or (ts_range[0] <= subtitle['end'] <= ts_range[1]) or (subtitle['start'] <= ts_range[0] and subtitle['end'] >= ts_range[1]):\n",
        "                matching_subs.append(subtitle['text'])\n",
        "    return matching_subs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDx8ntjxL-7a"
      },
      "outputs": [],
      "source": [
        "def parse_jsonl(jsonl_path):\n",
        "    # Initialize empty lists for your data\n",
        "    queries_data = []\n",
        "    documents_data = []\n",
        "    query_rankings_data = []\n",
        "\n",
        "    with open(jsonl_path, 'r') as file:\n",
        "        for idx, line in enumerate(file):\n",
        "            data = json.loads(line)\n",
        "            # drop non text-based queries\n",
        "            if data['type'] not in ['t']:\n",
        "                continue\n",
        "\n",
        "            # Find matching subtitles\n",
        "            matching_subs = find_matching_subtitles(data['vid_name'], data['ts'], subtitles_dict)\n",
        "            if matching_subs == []:\n",
        "                continue\n",
        "\n",
        "            # Extract data for the Query Set DataFrame\n",
        "            queries_data.append({'qid': data['desc_id'], 'query': data['desc']})\n",
        "\n",
        "            # Extract data for the Documents Set DataFrame, including matching subtitles\n",
        "            documents_data.append({'docno': idx, 'vid_name': data['vid_name'], 'ts': data['ts'],\n",
        "                                'duration': data['duration'], 'type': data['type'], 'text': \"\".join(matching_subs)})\n",
        "\n",
        "            # Extract data for the Query Rankings DataFrame\n",
        "            query_rankings_data.append({'qid': data[\"desc_id\"], 'query': data['desc'], 'docno': idx, 'rank': 1, 'score': 1.0})\n",
        "\n",
        "    return queries_data, documents_data, query_rankings_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU_Us_DWL-7a"
      },
      "outputs": [],
      "source": [
        "train_queries_data, train_documents_data, train_query_rankings_data = parse_jsonl(jsonl_train_path)\n",
        "\n",
        "# Convert lists to DataFrames (training)\n",
        "train_query_set_df = pd.DataFrame(train_queries_data)\n",
        "train_documents_set_df = pd.DataFrame(train_documents_data)\n",
        "train_query_rankings_df = pd.DataFrame(train_query_rankings_data)\n",
        "\n",
        "val_queries_data, val_documents_data, val_query_rankings_data = parse_jsonl(jsonl_val_path)\n",
        "\n",
        "# Convert lists to DataFrames (validation)\n",
        "val_query_set_df = pd.DataFrame(val_queries_data)\n",
        "val_documents_set_df = pd.DataFrame(val_documents_data)\n",
        "val_query_rankings_df = pd.DataFrame(val_query_rankings_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTiDgmaqL-7a",
        "outputId": "cdd8b431-1446-4f12-e41b-8131683db4aa"
      },
      "outputs": [],
      "source": [
        "#print the length of the dataframes\n",
        "print(len(train_query_set_df))\n",
        "print(len(train_documents_set_df))\n",
        "print(len(train_query_rankings_df))\n",
        "\n",
        "print(len(val_query_set_df))\n",
        "print(len(val_documents_set_df))\n",
        "print(len(val_query_rankings_df))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCaV5vcXL-7a"
      },
      "source": [
        "### First Stage Retrieval [TODO: BOX]\n",
        "The following part of the code will define three different first stage retrieval pipelines as an input for the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-SsgPJwVMXw",
        "outputId": "d3e0760a-6892-4d05-f38c-821e9364b978"
      },
      "outputs": [],
      "source": [
        "if not pt.started():\n",
        "    pt.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ATVHECDfY6U"
      },
      "outputs": [],
      "source": [
        "train_documents_set_df['docno'] = train_documents_set_df['docno'].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx55BjIGfNNa"
      },
      "outputs": [],
      "source": [
        "# Create an index\n",
        "from pathlib import Path\n",
        "\n",
        "indexer = pt.IterDictIndexer(\n",
        "    \"./index_path/\",\n",
        "    meta={\n",
        "        \"docno\": 16,\n",
        "        \"vid_name\": 64,\n",
        "        \"text\": 131072,\n",
        "    },\n",
        "    stemmer=\"porter\",\n",
        "    stopwords=\"terrier\",\n",
        "    overwrite=True,\n",
        "    # type=pt.index.IndexingType.MEMORY,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1W-_BFDjpqS"
      },
      "outputs": [],
      "source": [
        "joint_documents_set_df = pd.concat([train_documents_set_df, val_documents_set_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_PnpogfjpqS",
        "outputId": "2b494455-4836-4157-faf8-d1da376177dc"
      },
      "outputs": [],
      "source": [
        "indexed = indexer.index(joint_documents_set_df.to_dict('records'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xuAPswuVQMe"
      },
      "outputs": [],
      "source": [
        "# Initialize BatchRetrieve with the created index and specify BM25 as the weighting model\n",
        "first_stage_bm25 = pt.BatchRetrieve(\n",
        "    indexed,\n",
        "    wmodel=\"BM25\",\n",
        "    num_results=2,\n",
        "    metadata=[\"docno\", \"vid_name\", \"text\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2QEzXDSmPiC"
      },
      "outputs": [],
      "source": [
        "# Initialize BatchRetrieve with the created index and specify LemurTF_IDF as the weighting model\n",
        "first_stage_lemurtfidf = pt.BatchRetrieve(\n",
        "    indexed,\n",
        "    wmodel=\"LemurTF_IDF\",\n",
        "    num_results=2,\n",
        "    metadata=[\"docno\", \"vid_name\", \"text\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vCeCMoUvedO"
      },
      "source": [
        "# Computing feature\n",
        "The weighting model can be use in [pt.weighting_model.package: http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTBZtHYLy_fH"
      },
      "outputs": [],
      "source": [
        "# features, can use any of the features in the list\n",
        "\n",
        "pl2_retriever = pt.BatchRetrieve(indexed, wmodel=\"PL2\")\n",
        "dph_retriever = pt.BatchRetrieve(indexed, wmodel=\"DPH\")\n",
        "tf_idf_retriever = pt.BatchRetrieve(indexed, wmodel=\"TF_IDF\")\n",
        "bb2_retriever = pt.BatchRetrieve(indexed, wmodel=\"BB2\")\n",
        "ifb2_retriever = pt.BatchRetrieve(indexed, wmodel=\"IFB2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYrqwBx1vVn_"
      },
      "outputs": [],
      "source": [
        "# build a pipeline with the features\n",
        "pipeline_with_features = ~first_stage_bm25 >> (\n",
        "    pl2_retriever ** dph_retriever ** tf_idf_retriever ** bb2_retriever ** ifb2_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY5-uOFjmt8h"
      },
      "outputs": [],
      "source": [
        "# build a pipeline with the features\n",
        "pipeline_with_features = ~first_stage_lemurtfidf >> (\n",
        "    pl2_retriever ** dph_retriever ** tf_idf_retriever ** bb2_retriever ** ifb2_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE1WrfC8zJjm"
      },
      "outputs": [],
      "source": [
        "# Prepare the queries for the pipeline, remove special characters and extra spaces\n",
        "prepared_queries = train_query_set_df\n",
        "prepared_queries['qid'] = prepared_queries['qid'].astype(str)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "prepared_rankings = train_query_rankings_df.reset_index()\n",
        "prepared_rankings['qid'] = prepared_rankings['qid'].astype(str)\n",
        "prepared_rankings['docno'] = prepared_rankings['docno'].astype(str)\n",
        "prepared_rankings['query'] = prepared_rankings['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_rankings['query'] = prepared_rankings['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "prepared_rankings['query'] = prepared_rankings['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "prepared_rankings['label'] = prepared_rankings['score']\n",
        "\n",
        "prepared_rankings['label'] = prepared_rankings['label'].astype(int)\n",
        "\n",
        "prepared_valqueries = val_query_set_df.reset_index()\n",
        "prepared_valqueries['qid'] = prepared_valqueries['qid'].astype(str)\n",
        "prepared_valqueries['query'] = prepared_valqueries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_valqueries['query'] = prepared_valqueries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "\n",
        "prepared_valqueries['query'] = prepared_valqueries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "prepared_valrankings = val_query_rankings_df.reset_index()\n",
        "prepared_valrankings['qid'] = prepared_valrankings['qid'].astype(str)\n",
        "prepared_valrankings['docno'] = prepared_valrankings['docno'].astype(str)\n",
        "prepared_valrankings['query'] = prepared_valrankings['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_valrankings['query'] = prepared_valrankings['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "prepared_valrankings['query'] = prepared_valrankings['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "prepared_valrankings['label'] = prepared_valrankings['score']\n",
        "# make the label an int\n",
        "prepared_valrankings['label'] = prepared_valrankings['label'].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeKG_RmLXDIA"
      },
      "outputs": [],
      "source": [
        "# divided in batch\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# batch_size = 100\n",
        "# n_batches = (len(prepared_queries) + batch_size - 1) // batch_size\n",
        "\n",
        "# for batch_num in tqdm(range(n_batches), desc=\"Processing batches\"):\n",
        "#     start_idx = batch_num * batch_size\n",
        "#     end_idx = start_idx + batch_size\n",
        "#     batch_queries = prepared_queries[start_idx:end_idx]\n",
        "\n",
        "#     # run pipeline\n",
        "#     batch_results = pipeline_with_features(batch_queries)\n",
        "\n",
        "#     # write or append\n",
        "#     mode = 'w' if batch_num == 0 else 'a'\n",
        "#     header = True if batch_num == 0 else False\n",
        "\n",
        "#     # to csv\n",
        "#     batch_results.to_csv('results_with_features.csv', mode=mode, header=header, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLeXGDj8rGcx"
      },
      "source": [
        "Storage format: .csv or trec\n",
        "\n",
        "trec(https://pyterrier.readthedocs.io/en/latest/io.html): The pt io format, but it doesn't contain feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vOyqSXLOlkl",
        "outputId": "b5347def-45d4-47af-94e0-27cc93ea2d7a"
      },
      "outputs": [],
      "source": [
        "results_with_features = pipeline_with_features(prepared_queries)\n",
        "results_with_features.to_csv('lemurtf_idf_with_all_features.csv', mode='w', header=True, index=False)\n",
        "pt.io.write_results(results_with_features, 'lemurtf_idf_with_all_features_ptio')\n",
        "print(results_with_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5tgRqDUL-7c"
      },
      "source": [
        "### Learning [TODO: ROB]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrdQOXQ3L-7c"
      },
      "source": [
        "#### Definition of learned rankers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTHY4nOeL-7c"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "index = pt.IndexFactory.of(\"./index_path\")\n",
        "\n",
        "# load results from csv\n",
        "# results_with_features = pd.read_csv('/content/drive/MyDrive/IR/results_with_features.csv')\n",
        "fsr_pipelines = [\n",
        "    pipeline_with_features\n",
        "]\n",
        "\n",
        "learned_models = [\n",
        "    SVR()\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAfI165IL-7c"
      },
      "source": [
        "#### Rankers training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiUuKHweL-7c"
      },
      "outputs": [],
      "source": [
        "trained_models = [first_stage_bm25]\n",
        "names = ['BM25']\n",
        "\n",
        "# ltr_svm = ~pipeline_with_features >> pt.ltr.apply_learned_model(SVR())\n",
        "\n",
        "# ltr_svm.fit(\n",
        "#     prepared_queries,\n",
        "#     train_query_rankings_df,\n",
        "#     # train_documents_set_df\n",
        "# )\n",
        "\n",
        "for fsr_pipeline in fsr_pipelines:\n",
        "    for model in learned_models:\n",
        "        names.append(f\"prova_{model.__class__.__name__}\")\n",
        "        pipe = fsr_pipeline >> pt.ltr.apply_learned_model(model)\n",
        "        pipe.fit(\n",
        "            prepared_queries,\n",
        "            prepared_rankings\n",
        "        )\n",
        "        trained_models.append(pipe)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5_lc-2L-7c"
      },
      "source": [
        "#### Rankers evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3-fTOmcjL-7c",
        "outputId": "ddb49c07-4e68-4c8b-dc98-98af8981f1b2"
      },
      "outputs": [],
      "source": [
        "from pyterrier.measures import nDCG, RR, MAP\n",
        "\n",
        "pt.Experiment(\n",
        "    trained_models,\n",
        "    prepared_valqueries,\n",
        "    prepared_valrankings,\n",
        "    names=['BM25', 'BM25 > SVR'],\n",
        "    eval_metrics=[nDCG @ 3, RR @ 3, MAP],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMnU12yIjpqT",
        "outputId": "bcbe873b-9063-4a46-82bb-646eaa18dfa2"
      },
      "outputs": [],
      "source": [
        "\n",
        "pt.Experiment(\n",
        "    trained_models,\n",
        "    prepared_queries,\n",
        "    prepared_rankings,\n",
        "    names=['BM25', 'BM25 > SVR'],\n",
        "    eval_metrics=[nDCG @ 3, RR @ 3, MAP],\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
